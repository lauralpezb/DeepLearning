{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/iebs-logo.jpg\" alt=\"Logo IEBS\" align=\"center\">\n",
    "<br><br>\n",
    "<h1><font color=\"#113D68\" size=5>Análisis predictivo con Deep Learning</font></h1>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#113D68\" size=6>Caso Práctico: Análisis problema de clasificación con Deep Learning</font></h1>\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font size=3>Laura Cristina López Bedoya</font><br>\n",
    "<font size=3>Caso práctico</font><br>\n",
    "<font size=3>IEBS</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "* [Caso práctico](#section1)\n",
    "    - [Parte obligatoria](#section1.1)\n",
    "    - [Parte opcional](#section1.2)\n",
    "    - [Objetivos](#section1.3)\n",
    "    - [Criterios de entrega](#section1.4)\n",
    "    - [Temporalización](#section1.5)\n",
    "* [CIFAR10 Dataset](#section2)\n",
    "* [Experimentos con redes neuronales densas](#section3)\n",
    "    - [Experimento 1](section3.1)\n",
    "    - [Experimento 2](section3.2)\n",
    "* [Experimentos con CNNs](#section4)\n",
    "    - [Experimento 3](section4.1)\n",
    "    - [Experimento 4](section4.2)\n",
    "* [Experimento Opcional](#section5)\n",
    "* [Conclusión](#section6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Para mostrar gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Anaconda fixing problem\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fnreb9XA3Nsp"
   },
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Caso práctico</font>\n",
    "\n",
    "El objetivo de este caso práctico es simular como se haría un análisis completo de un problema para resolverlo con Deep Learning. Nos pondremos en la piel de un *data scientist* dedicado a analizar y crear modelos de Deep Learning para pasarlos a producción y ser desplegados en una aplicación.\n",
    "\n",
    "Imaginemos que tenemos un dataset completo que queremos explotar, nuestra labor será coger este dataset de imágenes (CIFAR10) y realizar varios experimentos con distintas redes para descubrir cual funciona mejor y cual elegimos para pasar a producción. Por lo que además de tener que entrerar distintas redes y entender qué ha pasado en cada entrenamiento explicando el resultado, al final deberemos justificar cual de todos los modelos entrenados es el más óptimo para pasar a producción.\n",
    "\n",
    "Cada experimento que tendremos que realizar estará bien definido, la red que deberéis crear y entrenar será proporcionada por lo que solamente tendréis que crear la red que se nos indica con TensorFlow y realizar el entrenamiento de la misma. Por cada experimento deberéis de sacar conclusiones de cómo de bueno o malo ha sido ese entrenamiento. Al final de todos los experimentos, deberemos de generar una pequeña documentación donde justificamos cual de los modelos entrenados es el más óptimo para pasar a producción.\n",
    "\n",
    "<a id=\"section1.1\"></a>\n",
    "# <font color=\"#004D7F\" size=4>Parte obligatoria</font>\n",
    "\n",
    "Será obligatorio realizar cada uno de los experimentos que están definidos. En cada experimento está definida la red que se tiene que crear y la configuración con la que se tiene que entrenar, por lo que solamente tendréis que pasar esa definición a código con TensorFlow. Al finalizar cada experimento se deberá genera una pequeña documentación explicando cómo ha sido el entrenamiento y sacando conclusiones de los resultados.\n",
    "\n",
    "Al final, después de realizar cada uno de los experimentos, se deberá de generar una pequeña documentación justificando cual de los modelos entreados es el óptimo para ser desplegado en producción.\n",
    "\n",
    "Es muy importante destacar que el objetivo de este caso práctico no es que obtengáis unos resultados muy buenos, de echo los resultados que obtendréis son los pre-definidos por las redes que tenéis que hacer. El objetivo principal es que veáis como se aborda un problema para ser resuelto con Deep Learning, donde partimos de un dataset y un objetivo, y vamos realizando diferentes experimentos hasta encontrar la solución más óptima que podemos llegar a desplegar en producción. Además, otro objetivo es que entendáis que estáis haciendo y los resultados que obtenéis con cada experimento: sin son buenos o malos, si hay sobreajuste en los datos de entrenamiento, si nuestra red no termina por aprender, si nuestra red se estanca en algún punto y ya no aprende más, etc.\n",
    "\n",
    "Para tener una buena práctica en la realización de este caso práctico se ofrecen esta recomendaciones:\n",
    "\n",
    "- Utiliza correctamente el sistema de celdas de jupyter. La libreta está realizada de tal forma que solo tendréis que completar las celdas que se indican, ya sea con código o con texto en markdown. Se recomienda rellenar solamente las celdas indicadas para que quede un informe limpio y fácil de seguir. Si fuera necesario incluir más celdas por cualquier motivo se puede hacer pero realizarlo con cuidado para no ensuciar demasiado la libreta.\n",
    "<br><br>\n",
    "- Las redes que tendréis que crear en cada experimento son las vistas en clase, por lo que os podéis inspirar en los ejemplos vistos en los tutoriales. Os recomiendo que no copiéis y peguéis código tal cual, sino que lo escribáis por vuestra cuenta y entendáis lo que estáis haciendo en cada momento. Tomaros el tiempo que haga falta para entender cada paso.\n",
    "<br><br>\n",
    "- Comprueba que todo se ejecuta correctamente antes de enviar tu trabajo. La mejor forma de enviarlo es exportando la libreta a pdf o html para enviarla en un formato más profesional.\n",
    "\n",
    "\n",
    "<a id=\"section1.2\"></a>\n",
    "# <font color=\"#004D7F\" size=4>Parte opcional</font>\n",
    "La parte opcional se trata de que vosotros creéis vuestra propia red neuronal para obtener mejores resultados que los de la parte obligatoria. Obviamente no es obligatorio conseguir mejores resultados. Se os indicarán algunan pautas adicionales para poder crear vuestra propia red de la nada. ¡Esta parte podéis verla como un reto!\n",
    "\n",
    "<a id=\"section1.3\"></a>\n",
    "# <font color=\"#004D7F\" size=4>Objetivos</font>\n",
    "* Cargar y entender los datos del dataset CIFAR10 con los que se trabajarán.\n",
    "* Crear cada una de las redes indicadas en los experimentos.\n",
    "* Entrenar cada una de las redes creadas en los experimentos.\n",
    "* Escribir un pequeño texto explicando el resultado de cada entrenamiento.\n",
    "* Escribir un pequeño texto de conclusión al final del cuaderno justificando el modelo elegido para desplegar.\n",
    "\n",
    "<a id=\"section1.4\"></a>\n",
    "# <font color=\"#004D7F\" size=4>Criterios de entrega</font>\n",
    "Se deberá entregar una libreta de jupyter en formato html o pdf, el trabajo debe estar autocontenido, incluyendo código y texto explicativo para cada sección. \n",
    "\n",
    "<a id=\"section1.5\"></a>\n",
    "# <font color=\"#004D7F\" size=4>Temporalización</font>\n",
    "* Fase 1: Instala y familiarizate con todo el entorno de trabajo.\n",
    "* Fase 2: Cargar los datos y familizarizarse con ellos.\n",
    "* Fase 3: Realizar cada uno de los experimentos indicados.\n",
    "* Fase 4: Escribir un texto de conclusión al final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\" size=5>CIFAR10 dataset</font>\n",
    "\n",
    "Este dataset es el que hemos visto en la clase anterior y con el que trabajaremos en el caso práctico. Para refresarlo, es un dataset que contiene imágenes en color de objetos que tenemos que clasificar.\n",
    "\n",
    "El dataset de de imágenes CIFAR10 tiene las siguintes características:\n",
    "- Imágenes de 10 tipos de objetos: aviones, automóbiles, pájaros, gatos, ciervos, perros, ranas, caballos, barcos y camiones.\n",
    "- Imágenes en color, es decir, cada pixel tiene 3 valores entre 0 y 255, esos valores corresponden a los valores de RGB (Red, Green, Blue).\n",
    "- Imágenes de tamaño 32x32x3, 32x32 píxeles y 3 valores por pixel.\n",
    "- 50.000 imágenes para el entrenamiento y 10.000 imágenes para el test.\n",
    "\n",
    "<br><br>\n",
    "<img src=\"images/rgb-image.png\" align=\"center\" width=\"400\">\n",
    "\n",
    "Para empezar debemos descargar los datos de las bases de datos de Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1622,
     "status": "ok",
     "timestamp": 1585247912718,
     "user": {
      "displayName": "Daniel González Medina",
      "photoUrl": "",
      "userId": "13811012319715560188"
     },
     "user_tz": -60
    },
    "id": "7-9vhppH3Nsq",
    "outputId": "0b66ea1d-6451-452d-83e3-61b36a82b1f6"
   },
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos los valores entre 0 y 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPLETAR: familiarizate con el dataset accediendo a los elementos, viendo los tamaños, los valores, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualizar los datos\n",
    "def visualizar_img (imagen):\n",
    "    elem = plt.figure(figsize=(20,20))\n",
    "    index = np.random.randint(len(imagen), size=100)\n",
    "    for i in range(100):\n",
    "        elem.add_subplot(20,20,i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(imagen[index[i]].reshape([32,32,3]))\n",
    "    plt.show()\n",
    "    \n",
    "visualizar_img(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Numero de imagenes usadas para entrenamiento: \", x_train.shape[0])\n",
    "print(\"Tamaño de las imagenes de entrenamiento: \",x_train.shape[1:])\n",
    "print(\"Numero de imagenes usadas para prueba: \", x_test.shape[0])\n",
    "print(\"Tamaño de las imagenes de prueba: \", x_test.shape[1:])\n",
    "print(\"Tamaño del dato que se obtiene como resultado: \", y_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizar un dato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dato: \",labels[y_train[21][0]])\n",
    "\n",
    "dato=plt.figure(figsize=(2,2))\n",
    "plt.imshow(x_train[21].reshape([32, 32, 3]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "St2ah_ku3Ns9"
   },
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Experimentos con redes neuronales densas</font>\n",
    "A continuación, realizar 2 experimentos usando redes neuronales densas con las redes que se te indican en cada sección.\n",
    "\n",
    "<a id=\"section3.1\"></a>\n",
    "# <font color=\"#004D7F\" size=4>Experimento 1</font>\n",
    "\n",
    "Arquitectura de la red:\n",
    "\n",
    "- Capa de aplanado `Flatten` con entrada `(32,32,3)`\n",
    "- Capa densa `Dense` con 10 neuronas y función de activación _ReLU_\n",
    "- Capa de salida densa `Dense` con 10 neuronas y función de activación _Softmax_\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "\n",
    "- Optimizador: Adam con factor de entrenamiento 0.01\n",
    "- Función de error: `sparce_categorical_crossentropy`\n",
    "- Métricas: `accuracy`\n",
    "- Número de *epochs*: 20\n",
    "\n",
    "#### COMPLETAR: crear y entrena la red neuronal indicada arriba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (32,32,3)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Optimizador\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "#Compilar modelo\n",
    "model1.compile(optimizer=opt,\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "#Entrenar el modelo\n",
    "modelfit = model1.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar el modelo\n",
    "fig=plt.figure(figsize=(70, 30))\n",
    "\n",
    "fig.add_subplot(10, 10, 1)\n",
    "plt.plot(modelfit.history['loss'], label='loss')\n",
    "plt.plot(modelfit.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(10, 10, 2)\n",
    "plt.plot(modelfit.history['accuracy'], label='acc')\n",
    "plt.plot(modelfit.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPLETAR: escribe un pequeño texto con los resultado obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la red neuronal anterior se entrenaron 30,840 parámetros.\n",
    "Los resultados obtenidos en el entrenamiento tienen una precisión entre 9% y 10% para el conjunto de entrenamiento y un 10% para el conjunto de validación. \n",
    "En las gráficas podemos observar que el error varia poco para el conjunto de entrenamiento y prueba, sin embargo, el rendimiento del modelo para el conjunto de entrenamiento tiene grandes cambios y el de prueba permanece constante.\n",
    "Este modelo no presenta buenos resultados dado que la precisión es muy baja y el porcentaje de error es muy alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3.2\"></a>\n",
    "# <font color=\"#004D7F\" size=4>Experimento 2</font>\n",
    "\n",
    "Arquitectura de la red:\n",
    "\n",
    "- Capa de aplanado `Flatten` con entrada `(32,32,3)`.\n",
    "- Capa densa `Dense` con 32 neuronas y función de activación _ReLU_.\n",
    "- Capa densa `Dense` con 64 neuronas y función de activación _ReLU_.\n",
    "- Capa densa `Dense` con 128 neuronas y función de activación _ReLU_.\n",
    "- Capa de salida densa `Dense` con 10 neuronas y función de activación _Softmax_.\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "\n",
    "- Optimizador: Adam con factor de entrenamiento 0.001\n",
    "- Función de error: `sparce_categorical_crossentropy`.\n",
    "- Métricas: `accuracy`.\n",
    "- Número de _epochs_: 40\n",
    "\n",
    "#### COMPLETAR: crear y entrena la red neuronal indicada arriba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (32,32,3)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizador\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#Compilar modelo\n",
    "model2.compile(optimizer=opt,\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "#Entrenar el modelo\n",
    "modelfit2 = model2.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar el modelo\n",
    "fig=plt.figure(figsize=(70, 30))\n",
    "\n",
    "fig.add_subplot(10, 10, 1)\n",
    "plt.plot(modelfit2.history['loss'], label='loss')\n",
    "plt.plot(modelfit2.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(10, 10, 2)\n",
    "plt.plot(modelfit2.history['accuracy'], label='acc')\n",
    "plt.plot(modelfit2.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPLETAR: escribe un pequeño texto con los resultado obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la red neuronal anterior se entrenaron 110,058 parámetros.\n",
    "Los resultados obtenidos en el entrenamiento tienen una precisión de 45% para el conjunto de entrenamiento y un 41% para el conjunto de validación. \n",
    "En las gráficas podemos observar que el error disminuye para el conjunto de entrenamiento y prueba en cada iteración, además, el rendimiento del modelo para el conjunto de entrenamiento y el de prueba aumenta.\n",
    "Este modelo presenta mejores resultados que el anterior (ejercicio 1), sin embargo, en las gráficas se observa un sobreajuste dado que la precisión y el error presentan valores óptimos para los datos de entrenamiento que para los datos de prueba y en estos últimos la precisión disminuye y el error incrementar en las últimas iteraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Experimentos con CNNs</font>\n",
    "A continuación, realizar 2 experimentos usando redes convolucionales con las redes que se te indican en cada sección.\n",
    "\n",
    "<a id=\"section4.1\"></a>\n",
    "# <font color=\"#004D7F\" size=4>Experimento 3</font>\n",
    "\n",
    "Arquitectura de la red:\n",
    "\n",
    "- Capa convolucional `Conv2D` con 16 filtros/kernels, padding con relleno, activación *ReLU* y con entrada `(32,32,3)`\n",
    "- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.\n",
    "- Capa de aplanado `Flatten`.\n",
    "- Capa densa `Dense` con 64 neuronas y función de activación _ReLU_.\n",
    "- Capa densa `Dense` con 32 neuronas y función de activación _ReLU_.\n",
    "- Capa de salida densa `Dense` con 10 neuronas y función de activación _Softmax_.\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "\n",
    "- Optimizador: Adam con factor de entrenamiento 0.0001\n",
    "- Función de error: `sparce_categorical_crossentropy`.\n",
    "- Métricas: `accuracy`.\n",
    "- Número de _epochs_: 10\n",
    "\n",
    "#### COMPLETAR: crear y entrena la red neuronal indicada arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Definir la red:\n",
    "model3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "#Optimizador\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "#Compilar el modelo\n",
    "model3.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Entrenar el modelo\n",
    "modelfit3 = model3.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=10)\n",
    "\n",
    "#Visualizar el modelo\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar el modelo\n",
    "fig=plt.figure(figsize=(70, 30))\n",
    "\n",
    "fig.add_subplot(10, 10, 1)\n",
    "plt.plot(modelfit3.history['loss'], label='loss')\n",
    "plt.plot(modelfit3.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(10, 10, 2)\n",
    "plt.plot(modelfit3.history['accuracy'], label='acc')\n",
    "plt.plot(modelfit3.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPLETAR: escribe un pequeño texto con los resultado obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la red neuronal anterior se entrenaron 265,066 parámetros.\n",
    "Los resultados obtenidos tienen una precisión de 59% para el conjunto de entrenamiento y un 57% para el conjunto de validación. \n",
    "En las gráficas podemos observar que el error disminuye para el conjunto de entrenamiento y prueba en cada iteración, además, el rendimiento del modelo para el conjunto de entrenamiento y el de prueba aumenta.\n",
    "Aunque los resultados obtenidos han sido buenos, el error presentado en el entrenamiento y en la validación es mayor a 1, por lo que no se recomienda el uso de este modelo.\n",
    "Este modelo presenta mejores resultados que los anteriores (ejercicio 1 y 2), en este caso la precisión aumenta con cada iteración y el modelo puede seguir aprendiendo, asimismo, el error disminuye con cada iteración para el entrenamiento y la validación del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4.2\"></a>\n",
    "# <font color=\"#004D7F\" size=4>Experimento 4</font>\n",
    "\n",
    "Arquitectura de la red:\n",
    "\n",
    "- Capa convolucional `Conv2D` con 32 filtros/kernels, padding con relleno, activación *ReLU* y con entrada `(32,32,3)`\n",
    "- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.\n",
    "- Capa convolucional `Conv2D` con 64 filtros/kernels, padding con relleno y activación *ReLU*\n",
    "- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.\n",
    "- Capa convolucional `Conv2D` con 64 filtros/kernels, padding con relleno y activación *ReLU*\n",
    "- Capa pooling `MaxPool2D` con reducción de 2 tanto en tamaño como en desplazamiento (stride) y padding con relleno.\n",
    "- Capa de aplanado `Flatten`.\n",
    "- Capa densa `Dense` con 64 neuronas y función de activación _ReLU_.\n",
    "- Capa de salida densa `Dense` con 10 neuronas y función de activación _Softmax_.\n",
    "\n",
    "Configuración del entrenamiento:\n",
    "\n",
    "- Optimizador: Adam con factor de entrenamiento 0.001\n",
    "- Función de error: `sparce_categorical_crossentropy`.\n",
    "- Métricas: `accuracy`.\n",
    "- Número de _epochs_: 20\n",
    "\n",
    "\n",
    "#### COMPLETAR: crear y entrena la red neuronal indicada arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Definir la red:\n",
    "model4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "#Optimizador\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#Compilar el modelo\n",
    "model4.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Entrenar el modelo\n",
    "modelfit4 = model4.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=20)\n",
    "\n",
    "#Visualizar el modelo\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar el modelo\n",
    "fig=plt.figure(figsize=(70, 30))\n",
    "\n",
    "fig.add_subplot(10, 10, 1)\n",
    "plt.plot(modelfit4.history['loss'], label='loss')\n",
    "plt.plot(modelfit4.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(10, 10, 2)\n",
    "plt.plot(modelfit4.history['accuracy'], label='acc')\n",
    "plt.plot(modelfit4.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPLETAR: escribe un pequeño texto con los resultado obtenidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la red neuronal anterior se entrenaron 122,570 parámetros.\n",
    "Los resultados obtenidos en el entrenamiento tienen una precisión del 90% para el conjunto de entrenamiento y un 73% para el conjunto de validación. \n",
    "En las gráficas podemos observar que el error disminuye para el conjunto de entrenamiento, pero aumenta para el conjunto de prueba en cada iteración, además, el rendimiento del modelo para el conjunto de entrenamiento aumenta y para el conjunto de prueba disminuye.\n",
    "El error del modelo es menor a 1 para el conjunto de entrenamiento, pero mayor a 1 para el conjunto de prueba.\n",
    "Aunque los resultados obtenidos han sido buenos, en las gráficas se observa un sobreajuste dado que la precisión y el error presentan valores óptimos para los datos de entrenamiento y no para los datos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Parte Opcional</font>\n",
    "Esta parte es totalmente opcional, se trata de realizar vuestra propia red neuronal con lo aprendido en clase para intentar mejorar lo aprendido en las anteriores redes o al menos acercarse a la red que mejor ha funcionado. El objetivo es que penséis en una posible red que creáis que puede funcionar y la pongáis en práctica para ver como funciona y expliquéis los resultados conseguido.\n",
    "\n",
    "También os animos a que utilicéis otro tipo de capas que no hemos visto en clase (aquí tenéis todas: https://www.tensorflow.org/api_docs/python/tf/keras/layers). Y en especial os recomiendo la capa de tipo `Dropout` (podéis saber más sobre esta capa aquí y como utilizarla aquí: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout).\n",
    "\n",
    "A grandes rasgos, la capa `Dropout` hace que determinadas neuronas no se activen/usen durante el proceso de entrenamiento en momentos determinados. De esta forma incitamos a que las neuronas que no aprenden tanto, lo hagan. De esta forma tenemos un entrenamiento más completo distribuido por todas las neuronas. Esta capa ayuda a evitar el problema de sobreajuste, es decir, que el entrenamiento sea demasiado ajustado al conjunto de *train* pero no sea tan óptimo en el conjunto de test.\n",
    "\n",
    "La capa `Dropout` se suele utilizar después de las capas de *Pooling*, y el valor que se suele dar es entre 0.1 y 0.5, que es el porcentaje de neuronas de la capa anterior que de forma aleatoria no se activan para ser entrendada. Por ejemplo, una capa `Dropout` tiene este aspecto:\n",
    "\n",
    "```\n",
    "...\n",
    "tf.keras.layers.Dropout(0.5)\n",
    "...\n",
    "```\n",
    "\n",
    "Podés saber más sobre este tipo de capa en este artículo: https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Definir la red:\n",
    "modelx = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(32,32,3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "#Optimizador\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#Compilar el modelo\n",
    "modelx.compile(optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Entrenar el modelo\n",
    "modelfitx = modelx.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=10)\n",
    "\n",
    "#Visualizar el modelo\n",
    "modelx.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar el modelo\n",
    "fig=plt.figure(figsize=(70, 30))\n",
    "\n",
    "fig.add_subplot(10, 10, 1)\n",
    "plt.plot(modelfitx.history['loss'], label='loss')\n",
    "plt.plot(modelfitx.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(10, 10, 2)\n",
    "plt.plot(modelfitx.history['accuracy'], label='acc')\n",
    "plt.plot(modelfitx.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la red neuronal anterior se entrenaron 282,250 parámetros.\n",
    "Los resultados obtenidos tienen una precisión del 77% para el conjunto de entrenamiento y un 72% para el conjunto de validación. \n",
    "En las gráficas podemos observar que el error disminuye para el conjunto de entrenamiento y para el conjunto de prueba en cada iteración, además, el rendimiento del modelo para el conjunto de entrenamiento y para el conjunto de prueba aumenta.\n",
    "El error del modelo es menor a 1 para ambos conjuntos de datos.\n",
    "Aunque los resultados obtenidos han sido buenos, se puede visualizar que en las últimas iteraciones los porcentajes no sufren grandes cambios y es posible que la red este llegando a un punto donde no aprenda más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\" size=5>Conclusión</font>\n",
    "Una vez realizado todos los experimentos anteriores, ¿qué modelo elegirías para desplegar en producción? ¿Por qué? \n",
    "\n",
    "Explica en breves palabras qué modelo eligirías para desplegar en producción y porqué. Compara cada experimento y extráis tus propias conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados han mejorado conforme se aumentan las capas en el modelo, creando redes más complejas y cambiando los hiperparámetros. Las redes convolucionales presentan mejores resultados que las redes densas, aunque para ambas redes se presentaron problemas de sobreajuste del modelo.\n",
    "De los 4 experimentos elegiría el modelo del experimento 3 para desplegar en producción. Este modelo presenta buenos resultados en los porcentajes de precisión, aunque el error el mayor a 1, sin embargo, este modelo ha un menor porcentaje de sobreajuste y la precisión para el conjunto de prueba y entrenamiento ha sido similar.\n",
    "Al elegir este modelo no significa que sea el óptimo o el más adecuado para el caso de estudio, se recomiendan hacer algunas modificaciones para mitigar un sobreajuste y evitar errores mayores en ambiente productivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 24px;\">\n",
    "    <img src=\"images/good-job.jpeg\">\n",
    "    <br>\n",
    "    ¡Si has llegado hasta aquí deberías estar super orgullos@!\n",
    "    <br><br>\n",
    "    Ya puedes relajar tus neuronas, les has dado mucho trabajo\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
